@Manual{R-AmesHousing,
  title = {AmesHousing: The Ames Iowa Housing Data},
  author = {Max Kuhn},
  year = {2017},
  note = {R package version 0.0.3},
}
@book{Sauer2019,
address = {Wiesbaden},
author = {Sauer, Sebastian},
isbn = {978-3-658-21586-6},
publisher = {Springer Gabler},
title = {{Moderne Datenanalyse mit R}},
year = {2019}
}
@article{VanBuuren2011,
abstract = {The R package mice imputes incomplete multivariate data by chained equations. The software mice 1.0 appeared in the year 2000 as an S-PLUS library, and in 2001 as an R package. mice 1.0 introduced predictor selection, passive imputation and automatic pooling. This article documents mice 2.9, which extends the functionality of mice 1.0 in several ways. In mice 2.9, the analysis of imputed data is made completely general, whereas the range of models under which pooling works is substantially extended. mice 2.9 adds new functionality for imputing multilevel data, automatic predictor selection, data handling, post-processing imputed values, specialized pooling routines, model selection tools, and diagnostic graphs. Imputation of categorical data is improved in order to bypass problems caused by perfect prediction. Special attention is paid to transformations, sum scores, indices and interactions using passive imputation, and to the proper setup of the predictor matrix. mice 2.9 can be downloaded from the Comprehensive R Archive Network. This article provides a hands-on, stepwise approach to solve applied incomplete data problems.},
author = {van Buuren, Stef and Groothuis-Oudshoorn, Karin},
doi = {10.18637/jss.v045.i03},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Chained equations,Fully conditional specification,Gibbs sampler,MICE,Multiple imputation,Passive imputation,Predictor selection,R},
month = {dec},
number = {3},
pages = {1--67},
title = {{mice: Multivariate imputation by chained equations in R}},
volume = {45},
year = {2011}
}
@book{Sheather2009,
author = {Sheather, Simon},
doi = {10.1007/978-0-387-09608-7},
isbn = {978-0-387-09607-0},
publisher = {Springer},
title = {{A Modern Approach to Regression with R}},
year = {2009}
}
@article{Beretta2016,
abstract = {Background: Nearest neighbor (NN) imputation algorithms are efficient methods to fill in missing data where each missing value on some records is replaced by a value obtained from related cases in the whole set of records. Besides the capability to substitute the missing data with plausible values that are as close as possible to the true value, imputation algorithms should preserve the original data structure and avoid to distort the distribution of the imputed variable. Despite the efficiency of NN algorithms little is known about the effect of these methods on data structure. Methods: Simulation on synthetic datasets with different patterns and degrees of missingness were conducted to evaluate the performance of NN with one single neighbor (1NN) and with k neighbors without (kNN) or with weighting (wkNN) in the context of different learning frameworks: plain set, reduced set after ReliefF filtering, bagging, random choice of attributes, bagging combined with random choice of attributes (Random-Forest-like method). Results: Whatever the framework, kNN usually outperformed 1NN in terms of precision of imputation and reduced errors in inferential statistics, 1NN was however the only method capable of preserving the data structure and data were distorted even when small values of k neighbors were considered; distortion was more severe for resampling schemas. Conclusions: The use of three neighbors in conjunction with ReliefF seems to provide the best trade-off between imputation error and preservation of the data structure. The very same conclusions can be drawn when imputation experiments were conducted on the single proton emission computed tomography (SPECTF) heart dataset after introduction of missing data completely at random.},
author = {Beretta, Lorenzo and Santaniello, Alessandro},
doi = {10.1186/s12911-016-0318-z},
issn = {14726947},
journal = {BMC Medical Informatics and Decision Making},
month = {jul},
number = {Suppl 3},
publisher = {BioMed Central Ltd.},
title = {{Nearest neighbor imputation algorithms: A critical evaluation}},
url = {/pmc/articles/PMC4959387/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4959387/},
volume = {16},
year = {2016}
}
@article{Breiman1996,
abstract = {Bagging predictors is a method for generating multiple versions of a predictor and using these to get an aggregated predictor. The aggregation averages over the versions when predicting a numerical outcome and does a plurality vote when predicting a class. The multiple versions are formed by making bootstrap replicates of the learning set and using these as new learning sets. Tests on real and simulated data sets using classification and regression trees and subset selection in linear regression show that bagging can give substantial gains in accuracy. The vital element is the instability of the prediction method. If perturbing the learning set can cause significant changes in the predictor constructed, then bagging can improve accuracy. {\textcopyright} 1996 Kluwer Academic Publishers,.},
author = {Breiman, Leo},
doi = {10.1007/bf00058655},
issn = {08856125},
journal = {Machine Learning},
keywords = {Aggregation,Averaging,Bootstrap,Combining},
number = {2},
pages = {123--140},
publisher = {Springer Netherlands},
title = {{Bagging predictors}},
url = {https://link.springer.com/article/10.1007/BF00058655},
volume = {24},
year = {1996}
}
@article{Greenwell2018,
abstract = {In the era of "big data", it is becoming more of a challenge to not only build state-of-the-art predictive models, but also gain an understanding of what's really going on in the data. For example, it is often of interest to know which, if any, of the predictors in a fitted model are relatively influential on the predicted outcome. Some modern algorithms---like random forests and gradient boosted decision trees---have a natural way of quantifying the importance or relative influence of each feature. Other algorithms---like naive Bayes classifiers and support vector machines---are not capable of doing so and model-free approaches are generally used to measure each predictor's importance. In this paper, we propose a standardized, model-based approach to measuring predictor importance across the growing spectrum of supervised learning algorithms. Our proposed method is illustrated through both simulated and real data examples. The R code to reproduce all of the figures in this paper is available in the supplementary materials.},
archivePrefix = {arXiv},
arxivId = {1805.04755},
author = {Greenwell, Brandon M. and Boehmke, Bradley C. and McCarthy, Andrew J.},
eprint = {1805.04755},
month = {may},
title = {{A Simple and Effective Model-Based Variable Importance Measure}},
url = {http://arxiv.org/abs/1805.04755},
year = {2018}
}
@book{Tibshirani2013,
address = {New York, New York, USA},
author = {Tibshirani, Gareth James and Daniela Witten and Trevor Hastie and Robert},
doi = {10.1007/978-1-4614-7138-7},
isbn = {978-1-4614-7137-0},
publisher = {Springer Science and Business Media},
title = {{An Introduction to Statistical Learning}},
year = {2013}
}






